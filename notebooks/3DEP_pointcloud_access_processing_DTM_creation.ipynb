{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "turkish-orchestra",
   "metadata": {},
   "source": [
    "# Programmatically accessing, processing, and visualizing USGS 3D Elevation Program (3DEP) data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3b420",
   "metadata": {},
   "source": [
    "<h2>Table of Contents<span class=\"tocSkip\"></span></h2>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Authors\" data-toc-modified-id=\"Authors-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Authors</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Funding\" data-toc-modified-id=\"Funding-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Funding</a></span></li><li><span><a href=\"#Keywords\" data-toc-modified-id=\"Keywords-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Keywords</a></span></li><li><span><a href=\"#Citation\" data-toc-modified-id=\"Citation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Citation</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Library-Imports\" data-toc-modified-id=\"Library-Imports-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Library Imports</a></span></li><li><span><a href= \"Define-Functions\" data-toc-modified-id=\"Define-Functions-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Define Functions</a></span></ul><li><span><a href=\"#Data-Access-and-Visualization\" data-toc-modified-id=\"Data-Access-and-Visualization-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Data Access and Visualization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Access-3DEP-Data\" data-toc-modified-id=\"Access-3DEP-Data-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Access 3DEP Data</a></span></li><li><span><a href=\"#Create-Interactive-Ipyleaflet-Map-And-Define-AOI\" data-toc-modified-id=\"Create-Interactive-Ipyleaflet-Map-And-Define-AOI-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Create Interactive Ipyleaflet Map and Define AOI</a></span></li><li><span><a href=\"Find-Intersecting-3DEP-Polygons\" data-toc-modified-id=\"Find-Interseciting-3DEP-Polygons-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Find Intersecting 3DEP Polygons</a></span></li></ul></li><li><span><a href=\"#Data-Processing\" data-toc-modified-id=\"Data-Processing-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Data Processing</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Conclusion</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Resources</a></span></li></div>\n",
    "    \n",
    "\n",
    "<h2>Authors</h2>\n",
    "<a id='#Authors'></a>\n",
    "\n",
    "<h2>Purpose</h2>\n",
    "<a id='#Purpose'></a>\n",
    "\n",
    "The United States Geological Survey's 3-D Elevation Program (3DEP)is an ongoing effort to provide high-quality topographic -- light detection and ranging (lidar) -- data for the entire conterminous United States, Hawaii, the U.S territories, and Interferometric Synthetic Aperture Radar (IfSAR) for Alaska over an 8-year period. Data acquisition is ongoing, with over 1800 3DEP datasets consisting of >42 trillion points covering an area of > 6 million $km^{2}$ already available for use.\n",
    "\n",
    "3DEP point cloud data can be downloaded on the web from a variety of resources including the <a href=\"https://portal.opentopography.org/datasets\">OpenTopography Portal</a> (restricted to academic users) and the <a href=\"https://prd-tnm.s3.amazonaws.com/LidarExplorer/index.html#/process\">USGS Lidar Explorer</a>. Due to limited computational resources, these web services implement limits on the spatial extent over which point cloud data may be accessed for a single job. In some cases, however, it may benefit users seeking raw, uprocessed point cloud data over large extents to be able to programmatically access, process, and visualize 3DEP point cloud data from a specific area of interest on their local workstation without the web service limitations. \n",
    "\n",
    "This Jupyter notebook is one of two developed focusing on enhancing access and usability of 3DEP data and derivative products. This notebook provides functions, pipelines, and overall workflow for effectively and efficiently accessing documents a Python-based workflow for accessing, processing, and visualizing 3DEP data, leveraging available APIs and cloud resources.\n",
    "\n",
    "<h4>Specific features of this notebook</h4>\n",
    "\n",
    "- Users may (1) select an area of interest (AOI) directly in an interactive map within this notebook; (2) import a shapefile or geoJSON file; or (3) directly input coordinate boundaries for their region of interest.\n",
    "\n",
    "- The relevant 3DEP dataset is accessed via the Amazon Web Services (AWS) API and point cloud data (stored as Entwine tiles) are accessed programmatically, clipped to the user-defined AOI and made available for subsequent processing.\n",
    "\n",
    "- Flexibile and customizable PDAL pipelines are available for classifying, processing, and computing derivate products based on user-defined specifications. \n",
    "\n",
    "- Point cloud data and/or derivative products are saved to local directory or local path defined by user.\n",
    "\n",
    "<h4>Additional resources</h4>\n",
    "An additional Python-based workflow has been developed and is availble in Jupyter Notebook format for <a href=\"http://localhost:8888/notebooks/Programmatically_accessing_3DEP_data_using_USGS_7.5_Quadrangles.ipynb\"> accessing 3DEP point cloud data for specific USGS 7.5' quadrangle footprints</a>.\n",
    "\n",
    "<h2>Funding</h2>\n",
    "<a id='#Funding'></a>\n",
    "OpenTopography is supported by the National Science Foundation under Award Numbers 1948997, 1948994 & 1948857. Funding for 3DEP workflow developement entitled \"Enhancing usability of 3DEP data and web services with Jupyter notebooks\"  was provided through the Community for Data Integration (CDI).\n",
    "\n",
    "<h2>Keywords</h2>\n",
    "<a id='#Keywords'></a>\n",
    "\n",
    "keywords=[\"OpenTopography\",\"USGS\", \"3DEP\", \"PDAL\"]\n",
    "\n",
    "<h2>Citation</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83dbc2a",
   "metadata": {},
   "source": [
    "## 6. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-vampire",
   "metadata": {},
   "source": [
    "<h3> 6.1 Library Imports</h3>\n",
    "<a id='#Library-Imports-6.1'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "champion-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdal\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, GeoJSON, basemaps, basemap_to_tiles, projections\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, interact, interactive, fixed, interact_manual, HBox, VBox, Label\n",
    "from osgeo import gdal\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "from shapely.ops import transform\n",
    "import requests\n",
    "import pyproj\n",
    "from pyproj.aoi import AreaOfInterest\n",
    "from pyproj.database import query_utm_crs_info\n",
    "from tqdm import tqdm\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1299e5e",
   "metadata": {},
   "source": [
    "<h3>6.2 Define Functions</h3>\n",
    "<a id='#Define-Functions-6.2'></a>\n",
    "\n",
    "The functions below are used throughout the rest of the notebook and are included here for clarity.\n",
    "\n",
    "```gcs_to_proj()``` is a function to project from geographic coordinates, WGS84 (EPSG: 4326), to Web Mercator projection (EPSG: 3857).\n",
    "\n",
    "```handle_draw()``` is a function for interactive drawing on ipyleaflet maps and storing the polygon for use in requesting point cloud data.\n",
    "\n",
    "```build_pdal_pipeline()``` is a function used to construct the pdal pipeline to request/process the point cloud data from AWS\n",
    "\n",
    "These functions can be modified as the user sees fit; however, they are designed to work 'out of the box'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d924c977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gcs_to_proj(poly):\n",
    "    \"\"\"\n",
    "    Function for reprojecting polygon shapely object from geographic coordinates (EPSG:4326) \n",
    "    to Web Mercator (EPSG3857)). \n",
    "    \"\"\"\n",
    "    wgs84 = pyproj.CRS(\"EPSG:4326\")\n",
    "    web_mercator = pyproj.CRS(\"EPSG:3857\")\n",
    "    project = pyproj.Transformer.from_crs(wgs84, web_mercator, always_xy=True).transform\n",
    "    user_poly_proj3857 = transform(project, poly)\n",
    "    return(user_poly_proj3857)\n",
    "\n",
    "def handle_draw(target, action, geo_json):\n",
    "    \"\"\"\n",
    "    Allow user to draw area of interest (AOI) on interactive ipyleaflet map.\n",
    "    \n",
    "    Parameters:\n",
    "        extent_epsg3857: polygon for user-defined AOI\n",
    "        usgs_3dep_dataset_name: name of 3DEP dataset which AOI overlaps\n",
    "        resolution:\n",
    "    \"\"\"\n",
    "    geom = dict(geo_json['geometry'])\n",
    "    user_poly = shape(geom)\n",
    "    user_poly_proj3857 = gcs_to_proj(user_poly)\n",
    "    print('AOI is valid and has boundaries of ', user_poly_proj3857.bounds)\n",
    "    user_AOI.append((user_poly, user_poly_proj3857))  #for various reasons, we need user AOI in GCS and EPSG 3857\n",
    "\n",
    "def build_pdal_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pointcloud_resolution, filterNoise = False,\n",
    "                        savePointCloud = True, pc_outName = 'filter_test', pc_outType = 'laz'):\n",
    "\n",
    "    \"\"\"\n",
    "    Build pdal pipeline for requesting, processing, and saving point cloud data.\n",
    "    \n",
    "    Parameters:\n",
    "        extent_epsg3857: Polygon for user-defined AOI in Web Mercator projection (EPS:3857)\n",
    "                         usgs_3dep_dataset_name: name of 3DEP dataset which AOI overlaps. Polygon is generated \n",
    "                         either through the 'handle_draw' methor or by inputing their own coordinates.\n",
    "        products: A list of the desired processing/products requested by the user. Based on\n",
    "                  this list, the appropiate processing pipeline is enabled.\n",
    "                  \n",
    "                  Options include: Classification, Filtering, MakeDTM, MakeDSM, etc...\n",
    "                  If 'products' is not indicated, the pipeline requests the data for \n",
    "                  the user-defined AOI and downloads as LAS/LAZ without any additional processing. \n",
    "        filterNoise: Optional argument that removes points of class 7 (noise). \n",
    "        pc_outName:  Desired name of file on user's local filesystem. If savePointcloud = False, \n",
    "                  this should be outName = ''\n",
    "        pc_outType:  Desired file extension. Input must be either 'las' or 'laz'. If a different file type is requested,\n",
    "                  the user will get error stating \"Extension must be 'las' or 'laz'\". If savePointcloud = False, \n",
    "                  this should be outType = ''\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/{}/ept.json\".format(usgs_3dep_dataset_name)\n",
    "    \n",
    "    ### TODO: Add a reclassify method / SMRF filter stage.\n",
    "    ### TODO: Add an option to choose an output CRS\n",
    "    ### TODO: Add option to DEM function to specify the type of gridding method (E.g. Zmin, Zmean, Zmax, Zidw, ect)\n",
    "    \n",
    "    #this is the basic pipeline which only accesses the 3DEP data. There is an optional\n",
    "    pointcloud_pipeline = {\n",
    "            \"pipeline\": [\n",
    "                \n",
    "                {\n",
    "                    \"type\": \"readers.ept\",\n",
    "                    \"filename\": str(url),\n",
    "                    \"polygon\": str(extent_epsg3857),\n",
    "                    \"requests\": 3,\n",
    "                    \"resolution\": pointcloud_resolution\n",
    "                }\n",
    "            ]\n",
    "    }\n",
    "    \n",
    "    if filterNoise == True:\n",
    "        \n",
    "        filter_stage = {\n",
    "            \"type\":\"filters.range\",\n",
    "            \"limits\":\"Classification![7:7]\"\n",
    "        }\n",
    "        \n",
    "        pointcloud_pipeline['pipeline'].append(filter_stage)\n",
    "    \n",
    "    if savePointCloud == True:\n",
    "        \n",
    "        if pc_outType == 'las':\n",
    "            savePC_stage = {\n",
    "                \"type\": \"writers.las\",\n",
    "                \"filename\": str(pc_outName)+'.'+ str(pc_outType)\n",
    "            }\n",
    "        elif pc_outType == 'laz':    \n",
    "            savePC_stage = {\n",
    "                \"type\": \"writers.las\",\n",
    "                \"compression\": \"laszip\",\n",
    "                \"filename\": str(pc_outName)+'.'+ str(pc_outType)\n",
    "            }\n",
    "        else:\n",
    "            raise Exception(\"pc_outType must be 'las' or 'laz'.\")\n",
    "\n",
    "        pointcloud_pipeline['pipeline'].append(savePC_stage)\n",
    "        \n",
    "    return pointcloud_pipeline\n",
    "\n",
    "\n",
    "def make_DEM_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pointcloud_resolution, dem_resolution,\n",
    "                      filterNoise = True, savePointCloud = False, pc_outName = 'filter_test', pc_outType = 'laz',\n",
    "                      demType = 'dtm', dem_outName = 'dem_test', dem_outExt = 'tif', driver = \"GTiff\"):\n",
    "    \n",
    "    dem_pipeline = build_pdal_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pointcloud_resolution,\n",
    "                                              filterNoise, savePointCloud, pc_outName, pc_outType)\n",
    "    \n",
    "    if demType == 'dsm':\n",
    "        dem_stage = {\n",
    "                \"type\":\"writers.gdal\",\n",
    "                \"filename\":str(dem_outName)+ '.' + str(dem_outExt),\n",
    "                \"gdaldriver\":driver,\n",
    "                \"nodata\":-9999,\n",
    "                \"output_type\":\"idw\",\n",
    "                \"resolution\":float(dem_resolution),\n",
    "                \"gdalopts\":\"COMPRESS=LZW,TILED=YES,blockxsize=256,blockysize=256,COPY_SRC_OVERVIEWS=YES\"\n",
    "        }\n",
    "    \n",
    "    elif demType == 'dtm':\n",
    "        groundfilter_stage = {\n",
    "                \"type\":\"filters.range\",\n",
    "                \"limits\":\"Classification[2:2]\"\n",
    "        }\n",
    "\n",
    "        dem_pipeline['pipeline'].append(groundfilter_stage)\n",
    "\n",
    "        dem_stage = {\n",
    "                \"type\":\"writers.gdal\",\n",
    "                \"filename\":str(dem_outName)+ '.' + str(dem_outExt),\n",
    "                \"gdaldriver\":driver,\n",
    "                \"nodata\":-9999,\n",
    "                \"output_type\":\"idw\",\n",
    "                \"resolution\":float(dem_resolution),\n",
    "                \"gdalopts\":\"COMPRESS=LZW,TILED=YES,blockxsize=256,blockysize=256,COPY_SRC_OVERVIEWS=YES\"\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"demType must be 'dsm' or 'dtm'.\")\n",
    "        \n",
    "        \n",
    "    dem_pipeline['pipeline'].append(dem_stage)\n",
    "        \n",
    "    return dem_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433ad51",
   "metadata": {},
   "source": [
    "## 7. Data Access and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ecbeb2",
   "metadata": {},
   "source": [
    "<h3> 7.1 Access 3DEP Data Polygons</h3>\n",
    "<a id='#Access-3DEP-Data-7.1'></a>\n",
    "3DEP lidar point cloud data are stored as Entwine tiles on \n",
    "\n",
    "Executing the next two cells will allow you to select a Area of Interest (AOI) for which point cloud data will be retreived. The map includes a Geo\n",
    "JSON file indicating where 3DEP point cloud data are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a267308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projecting 3DEP polygons to web mercator (EPSG:3857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1806/1806 [00:09<00:00, 183.48it/s]\n"
     ]
    }
   ],
   "source": [
    "### Get GeoJSON file for 3DEP outlines from URL \n",
    "\n",
    "#this needs to be modified to always make a new pull, even if it exists because it is possible updated at the source.\n",
    "if not os.path.exists('resources.geojson'):\n",
    "    url = 'https://raw.githubusercontent.com/hobuinc/usgs-lidar/master/boundaries/resources.geojson'\n",
    "    r = requests.get(url)\n",
    "    with open('resources.geojson', 'w') as f:\n",
    "        f.write(r.content.decode(\"utf-8\"))\n",
    "\n",
    "with open('resources.geojson', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "geo_json_3DEP = GeoJSON(data=data, style = {'color': 'green', 'opacity':1, \n",
    "                                       'weight':1.9, 'fillOpacity':0.1})\n",
    "\n",
    "with open('resources.geojson', 'r') as f:\n",
    "    df = gpd.read_file(f)\n",
    "\n",
    "projected_geoms = []\n",
    "\n",
    "print('projecting 3DEP polygons to web mercator (EPSG:3857)')\n",
    "for geometry in tqdm(df['geometry']):\n",
    "        projected_geoms.append(gcs_to_proj(geometry))\n",
    "\n",
    "#df['geometry_epsg3857'] = projected_geoms\n",
    "geometries_GCS = df['geometry']\n",
    "geometries_EPSG3857 = gpd.GeoSeries(projected_geoms)\n",
    "#geometries_EPSG3857 = df['geometry_epsg3857']\n",
    "names = df['name']\n",
    "urls = df['url']\n",
    "num_points = df['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86389e5e",
   "metadata": {},
   "source": [
    "<h3> 7.2 Create Interactive Ipyleaflet Map and Define AOI</h3>\n",
    "<a id='#Create-Interactive-Ipyleaflet-Map-And-Define-AOI-7.2'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c954b1",
   "metadata": {},
   "source": [
    "**TODO - Add a step where the user polygon is saved as geojson or shp.** <br>\n",
    "**TODO - Add four text boxes for custom user coordinates** <br>\n",
    "**TODO - Add a method for reading in a shapefile for bounding box** <br>\n",
    "**TODO - Remove the Circle and coordinate widget from the side bar**\n",
    "**TODO - Add a method for finding which 3DEP dataset is the 'most appropriate' given the coverage (if they are overlapping)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6f7cc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select an Area of Interest using the tools on the left side of the map\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3baf37dec74799a28f080208ad27bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39, -100], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOI is valid and has boundaries of  (-11739753.276419649, 4374379.156391584, -11732886.97890803, 4387044.484600398)\n"
     ]
    }
   ],
   "source": [
    "m = Map(\n",
    "    basemap=basemaps.Esri.WorldTopoMap,\n",
    "    center=(39, -100),\n",
    "    zoom=3,\n",
    "    crs=projections.EPSG3857\n",
    "    )\n",
    "\n",
    "m.add_layer(geo_json_3DEP)  #add 3DEP polygons GeoJSON\n",
    "\n",
    "dc = ipyleaflet.DrawControl(\n",
    "    marker={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "    rectangle={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "    circle={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "    circlemarker={},\n",
    ")\n",
    "\n",
    "print('Select an Area of Interest using the tools on the left side of the map')\n",
    "user_AOI = []\n",
    "dc.on_draw(handle_draw)\n",
    "m.add_control(dc)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff54758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421ec801d16d46e59e748a35e3b7b7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Map(center=[36.58549753357282, -105.43046487032619], controls=(ZoomControl(options=['position',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### this is where we want to zoom into the polygon\n",
    "AOI_GCS = user_AOI[0][0]\n",
    "AOI_EPSG3857 = user_AOI[0][1]\n",
    "centroid =  list(AOI_GCS.centroid.coords)[0]\n",
    "\n",
    "intersecting_polys = []\n",
    "for i,geom in enumerate(geometries_EPSG3857):\n",
    "    if geom.intersects(AOI_EPSG3857):\n",
    "        intersecting_polys.append((names[i], geometries_GCS[i], geometries_EPSG3857[i], urls[i], num_points[i]))\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.Esri.WorldTopoMap,\n",
    "    center=(centroid[1],centroid[0]),\n",
    "    zoom=12,\n",
    "    )\n",
    "\n",
    "wlayer_3DEP = ipyleaflet.WKTLayer(\n",
    "    wkt_string=intersecting_polys[0][1].wkt, \n",
    "    style={\"color\": \"green\"}, hover_style={\"fillColor\": \"red\"},\n",
    ")\n",
    "\n",
    "wlayer_user = ipyleaflet.WKTLayer(\n",
    "    wkt_string=AOI_GCS.boundary.wkt,\n",
    "    style={\"color\": \"blue\"}\n",
    ")\n",
    "\n",
    "AOI_EPSG3857_wtk = AOI_EPSG3857.wkt + f\" / EPSG:3857\"\n",
    "\n",
    "m.add_layer(wlayer_3DEP)\n",
    "m.add_layer(wlayer_user)\n",
    "\n",
    "num_pts_est = int((AOI_EPSG3857.area/intersecting_polys[0][2].area)*(intersecting_polys[0][4]))\n",
    "area = int(AOI_EPSG3857.area/1e6)\n",
    "usgs_3dep_dataset = intersecting_polys[0][0]\n",
    "\n",
    "widgets.VBox(\n",
    "    [m,\n",
    "        widgets.Label(value=f'Full dataset will consist of ~{num_pts_est:,} \\\n",
    "        points from the {usgs_3dep_dataset} 3DEP dataset, or choose desired resolution below.'),\n",
    "        user_resolution:=widgets.RadioButtons(\n",
    "            options=[\n",
    "                (f'Full - All ~{int(num_pts_est):,} points', 1.0),\n",
    "                (f'High - 2m resolution ~{int(num_pts_est/2):,} points', 2.0),\n",
    "                (f'Mid  - 5m resolution ~{int(num_pts_est/5):,} points', 5.0),\n",
    "                (f'Low  - 10m resolution ~{int(num_pts_est/10):,} points', 10.0)\n",
    "            ],\n",
    "            layout={'width': 'max-content'},\n",
    "            disabled = False,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3471de6",
   "metadata": {},
   "source": [
    "### Project to Web Mercator (EPSG: 3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a1e1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI_EPSG3857_wtk = AOI_EPSG3857.wkt + f\" / EPSG:3857\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990899f",
   "metadata": {},
   "source": [
    "## 8. Data Processing\n",
    "PDAL pipelines are useful ways of processing and manipulating point cloud data and creating derivative products. Below you will need to define the processing and/or derivative products which you desire. The ```build_pdal_pipeline()``` function will then construct the appropriate pipeline designed for the user's specifications. Executing this pipeline will request and perform processing on the point cloud data and provide the final result on the user's filesystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f17c46",
   "metadata": {},
   "source": [
    "### 8.1 Construct PDAL Pipeline\n",
    "The PDAL pipeline is constructed using the ```build_pdal_pipeline()``` function. Explanations of input parameters are can be found in this cell. Importantly, the ```outputs``` parameter is where the user may define the processing and outputs that they wish to produce. \n",
    "\n",
    "Options (**TODO: Build function capability to allow user to specify an end-product(s)**)  <br>\n",
    "```makeDTM```: Create a digital terrain model (DTM), also known as a bare-earth model <br>\n",
    "```makeDSM```: Create a digital surface model (DSM) <br>\n",
    "```reclassify```: Reclassify the point cloud (instead of using only the USGS classes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1555ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/Users/cole/Dropbox/unavco/project/ot_repo/OT_3DEP_Workflows/notebooks/resolution_tests/'\n",
    "pointcloud_resolution = user_resolution.value\n",
    "pc_pipeline = build_pdal_pipeline(AOI_EPSG3857_wtk, usgs_3dep_dataset, pointcloud_resolution, filterNoise = True,\n",
    "                        savePointCloud = True, pc_outName = dirname+'pc4_midres', pc_outType = 'laz')\n",
    "\n",
    "pc_pipeline = pdal.Pipeline(json.dumps(pc_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b0d7cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 51.9 s, sys: 4.34 s, total: 56.2 s\n",
      "Wall time: 59.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use streaming mode at 1e6 points at a time. This\n",
    "# helps us conserve memory for pipelines that are streamable\n",
    "# check that with the pipeline.streamable property\n",
    "results = pc_pipeline.execute_streaming(chunk_size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da107b41",
   "metadata": {},
   "source": [
    "If the user only desires point cloud data, they may stop here. Following is a quick overview showing how ground class may be gridded to create a DTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ed7a5",
   "metadata": {},
   "source": [
    "### 8.2 (Optional) DTM Gridding using USGS Classes\n",
    "The following pipeline reads in a las/laz, retains points corresponding to the current ground classification (ie no reclassification is done), and outputs a DTM geotiff. This pipeline may be built into a function(TODO)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d14512",
   "metadata": {},
   "source": [
    "### Make DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "963d15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_resolution = 2.0\n",
    "dirname = '/Users/cole/Dropbox/unavco/project/ot_repo/OT_3DEP_Workflows/notebooks/resolution_tests/dems/'\n",
    "dem_pipeline = make_DEM_pipeline(AOI_EPSG3857_wtk, usgs_3dep_dataset, pointcloud_resolution, dsm_resolution,\n",
    "                      filterNoise = True, savePointCloud = False, pc_outName = '', pc_outType = '', \n",
    "                      demType = 'dsm', dem_outName = dirname+'dsm_pc4_midres', dem_outExt = 'tif', driver = \"GTiff\")\n",
    "\n",
    "dem_pipeline = pdal.Pipeline(json.dumps(dem_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb294ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 18s, sys: 1min 32s, total: 3min 51s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = dem_pipeline.execute_streaming(chunk_size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d3fc2",
   "metadata": {},
   "source": [
    "### Make DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f788735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_resolution = 2.0\n",
    "dirname = '/Users/cole/Dropbox/unavco/project/ot_repo/OT_3DEP_Workflows/notebooks/resolution_tests/dems/'\n",
    "dem_pipeline = make_DEM_pipeline(AOI_EPSG3857_wtk, usgs_3dep_dataset, pointcloud_resolution, dtm_resolution,\n",
    "                      filterNoise = True, savePointCloud = False, pc_outName = '', pc_outType = '', \n",
    "                      demType = 'dtm', dem_outName = dirname+'dtm_pc4_midres', dem_outExt = 'tif', driver = \"GTiff\")\n",
    "\n",
    "dem_pipeline = pdal.Pipeline(json.dumps(dem_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3697eb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 44 s, total: 2min 9s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4418528"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dem_pipeline.execute_streaming(chunk_size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8990d5",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualize the DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dem_outName+'.'+dem_outExt\n",
    "gdal_data = gdal.Open(filename)\n",
    "gdal_band = gdal_data.GetRasterBand(1)\n",
    "nodataval = gdal_band.GetNoDataValue()\n",
    "\n",
    "# convert to a numpy array\n",
    "data_array = gdal_data.ReadAsArray().astype(float)\n",
    "data_array\n",
    "\n",
    "# replace missing values if necessary\n",
    "if np.any(data_array == nodataval):\n",
    "    data_array[data_array == nodataval] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13794fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (15,15))\n",
    "masked_array = np.ma.array (data_array, mask=np.isnan(data_array))\n",
    "cmap = matplotlib.cm.get_cmap(\"Greys\").copy()\n",
    "cmap.set_bad('white',1.)\n",
    "ax.imshow(masked_array, interpolation='nearest', cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c4c69",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf65c16",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d9300",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pdal_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pointcloud_resolution, filterNoise = False,\n",
    "                        savePointCloud = True, pc_outName = 'filter_test', pc_outType = 'laz'):\n",
    "\n",
    "    \"\"\"\n",
    "    Build pdal pipeline for requesting, processing, and saving point cloud data.\n",
    "    \n",
    "    Parameters:\n",
    "        extent_epsg3857: Polygon for user-defined AOI in Web Mercator projection (EPS:3857)\n",
    "                         usgs_3dep_dataset_name: name of 3DEP dataset which AOI overlaps. Polygon is generated \n",
    "                         either through the 'handle_draw' methor or by inputing their own coordinates.\n",
    "        products: A list of the desired processing/products requested by the user. Based on\n",
    "                  this list, the appropiate processing pipeline is enabled.\n",
    "                  \n",
    "                  Options include: Classification, Filtering, MakeDTM, MakeDSM, etc...\n",
    "                  If 'products' is not indicated, the pipeline requests the data for \n",
    "                  the user-defined AOI and downloads as LAS/LAZ without any additional processing. \n",
    "        filterNoise: Optional argument that removes points of class 7 (noise). \n",
    "        pc_outName:  Desired name of file on user's local filesystem. If savePointcloud = False, \n",
    "                  this should be outName = ''\n",
    "        pc_outType:  Desired file extension. Input must be either 'las' or 'laz'. If a different file type is requested,\n",
    "                  the user will get error stating \"Extension must be 'las' or 'laz'\". If savePointcloud = False, \n",
    "                  this should be outType = ''\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/{}/ept.json\".format(usgs_3dep_dataset_name)\n",
    "    \n",
    "    ## TODO: Add a reclassify method.\n",
    "    \n",
    "    #this is the basic pipeline which only accesses the 3DEP data. There is an optional\n",
    "    pointcloud_pipeline = {\n",
    "            \"pipeline\": [\n",
    "                \n",
    "                {\n",
    "                    \"type\": \"readers.ept\",\n",
    "                    \"filename\": str(url),\n",
    "                    \"polygon\": str(extent_epsg3857),\n",
    "                    \"requests\": 3,\n",
    "                    \"resolution\": pointcloud_resolution\n",
    "                }\n",
    "            ]\n",
    "    }\n",
    "    \n",
    "    if filterNoise == True:\n",
    "        \n",
    "        filter_stage = {\n",
    "            \"type\":\"filters.range\",\n",
    "            \"limits\":\"Classification![7:7]\"\n",
    "        }\n",
    "        \n",
    "        pointcloud_pipeline['pipeline'].append(filter_stage)\n",
    "    \n",
    "    if savePointCloud == True:\n",
    "        \n",
    "        if pc_outType == 'las':\n",
    "            savePC_stage = {\n",
    "                \"type\": \"writers.las\",\n",
    "                \"filename\": str(pc_outName)+'.'+ str(pc_outType)\n",
    "            }\n",
    "        elif pc_outType == 'laz':    \n",
    "            savePC_stage = {\n",
    "                \"type\": \"writers.las\",\n",
    "                \"compression\": \"laszip\",\n",
    "                \"filename\": str(pc_outName)+'.'+ str(pc_outType)\n",
    "            }\n",
    "        else:\n",
    "            raise Exception(\"pc_outType must be 'las' or 'laz'.\")\n",
    "\n",
    "        pointcloud_pipeline['pipeline'].append(savePC_stage)\n",
    "        \n",
    "    return pointcloud_pipeline\n",
    "\n",
    "\n",
    "def make_DTM_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pointcloud_resolution, dtm_resolution,\n",
    "                      filterNoise = True, savePointCloud = False, pc_outName = 'filter_test', pc_outType = 'laz',\n",
    "                      demType = 'dtm', dem_outName = 'dem_test', dem_outExt = 'tif', driver = \"GTiff\"):\n",
    "\n",
    "    ### TODO: smrf filter \n",
    "    \n",
    "    dem_pipeline = build_pdal_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pointcloud_resolution,\n",
    "                                              filterNoise, savePointCloud, pc_outName, pc_outType)\n",
    "    \n",
    "    if demType == 'dsm':\n",
    "        dem_stage = {\n",
    "                \"type\": \"writers.gdal\",\n",
    "                \"filename\":str(dem_outName)+ '.' + str(dem_outExt),\n",
    "                \"gdaldriver\":driver,\n",
    "                \"output_type\":\"min\",\n",
    "                \"resolution\":float(dtm_resolution),\n",
    "                \"gdalopts\":\"COMPRESS=LZW,TILED=YES,blockxsize=256,blockysize=256,COPY_SRC_OVERVIEWS=YES\"\n",
    "        }\n",
    "    \n",
    "    elif demType == 'dtm':\n",
    "        groundfilter_stage = {\n",
    "                \"type\":\"filters.range\",\n",
    "                \"limits\":\"Classification[2:2]\"\n",
    "        }\n",
    "\n",
    "        dem_pipeline['pipeline'].append(groundfilter_stage)\n",
    "\n",
    "        dem_stage = {\n",
    "                \"type\": \"writers.gdal\",\n",
    "                \"filename\":str(dem_outName)+ '.' + str(dem_outExt),\n",
    "                \"gdaldriver\":driver,\n",
    "                \"output_type\":\"min\",\n",
    "                \"resolution\":float(dtm_resolution),\n",
    "                \"gdalopts\":\"COMPRESS=LZW,TILED=YES,blockxsize=256,blockysize=256,COPY_SRC_OVERVIEWS=YES\"\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"demType must be 'dsm' or 'dtm'.\")\n",
    "        \n",
    "        \n",
    "    dem_pipeline['pipeline'].append(dem_stage)\n",
    "        \n",
    "    return dem_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2144c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = build_pdal_pipeline(AOI_EPSG3857_wtk, usgs_3dep_dataset, pointcloud_resolution, filterNoise = False,\n",
    "                        savePointCloud = True, pc_outName = 'filter_test', pc_outType = 'laz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_resolution = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aebbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_resolution = 5.0\n",
    "dem_pipeline = make_DTM_pipeline(AOI_EPSG3857_wtk, usgs_3dep_dataset, pointcloud_resolution, dtm_resolution,\n",
    "                      filterNoise = True, savePointCloud = False, pc_outName = '', pc_outType = '', \n",
    "                      demType = 'dsm', dem_outName = 'dsm_test', driver = \"GTiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea09c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_pipeline = pdal.Pipeline(json.dumps(dem_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_dem = dem_pipeline.execute_streaming(chunk_size=1000000)\n",
    "print(dem_pipeline.log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcloud",
   "language": "python",
   "name": "pointcloud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
