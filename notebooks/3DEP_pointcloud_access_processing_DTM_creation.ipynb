{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "turkish-orchestra",
   "metadata": {
    "VoilaConfiguration": {
     "show_tracebacks": true
    }
   },
   "source": [
    "# Programmatically accessing, processing, and visualizing USGS 3D Elevation Program (3DEP) data for user-defined area of interest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3b420",
   "metadata": {},
   "source": [
    "<h2>Table of Contents<span class=\"tocSkip\"></span></h2>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Authors\" data-toc-modified-id=\"Authors-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Authors</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Funding\" data-toc-modified-id=\"Funding-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Funding</a></span></li><li><span><a href=\"#Keywords\" data-toc-modified-id=\"Keywords-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Keywords</a></span></li><li><span><a href=\"#Citation\" data-toc-modified-id=\"Citation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Citation</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Library-Imports\" data-toc-modified-id=\"Library-Imports-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Library Imports</a></span></li><li><span><a href= \"Define-Functions\" data-toc-modified-id=\"Define-Functions-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Define Functions</a></span></ul><li><span><a href=\"#Data-Access-and-Visualization\" data-toc-modified-id=\"Data-Access-and-Visualization-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Data Access and Visualization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Access-3DEP-Data\" data-toc-modified-id=\"Access-3DEP-Data-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Access 3DEP Data</a></span></li><li><span><a href=\"#Create-Interactive-Ipyleaflet-Map-And-Define-AOI\" data-toc-modified-id=\"Create-Interactive-Ipyleaflet-Map-And-Define-AOI-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Create Interactive Ipyleaflet Map and Define AOI</a></span></li><li><span><a href=\"Find-Intersecting-3DEP-Polygons\" data-toc-modified-id=\"Find-Interseciting-3DEP-Polygons-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Find Intersecting 3DEP Polygons</a></span></li></ul></li><li><span><a href=\"#Data-Processing\" data-toc-modified-id=\"Data-Processing-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Data Processing</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Conclusion</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Resources</a></span></li></div>\n",
    "    \n",
    "\n",
    "<h2>Authors</h2>\n",
    "<a id='#Authors'></a>\n",
    "\n",
    "<h2>Purpose</h2>\n",
    "<a id='#Purpose'></a>\n",
    "\n",
    "The United States Geological Survey's 3-D Elevation Program (3DEP)is an ongoing effort to provide high-quality topographic -- light detection and ranging (lidar) -- data for the entire conterminous United States, Hawaii, the U.S territories, and Interferometric Synthetic Aperture Radar (IfSAR) for Alaska over an 8-year period. Data acquisition is ongoing, with over 1800 3DEP datasets consisting of >42 trillion points covering an area of > 6 million $km^{2}$ already available for use.\n",
    "\n",
    "3DEP point cloud data can be downloaded on the web from a variety of resources including the <a href=\"https://portal.opentopography.org/datasets\">OpenTopography Portal</a> (restricted to academic users) and the <a href=\"https://prd-tnm.s3.amazonaws.com/LidarExplorer/index.html#/process\">USGS Lidar Explorer</a>. Due to limited computational resources, these web services implement limits on the spatial extent over which point cloud data may be accessed for a single job. In some cases, however, it may benefit users seeking raw, uprocessed point cloud data over large extents to be able to programmatically access, process, and visualize 3DEP point cloud data from a specific area of interest on their local workstation without the web service limitations. \n",
    "\n",
    "This Jupyter notebook is one of two developed focusing on enhancing access and usability of 3DEP data and derivative products. This notebook provides functions, pipelines, and overall workflow for effectively and efficiently accessing documents a Python-based workflow for accessing, processing, and visualizing 3DEP data, leveraging available APIs and cloud resources.\n",
    "\n",
    "<h4>Specific features of this notebook</h4>\n",
    "\n",
    "- Users may (1) select an area of interest (AOI) directly in an interactive map within this notebook; (2) import a shapefile or geoJSON file; or (3) directly input coordinate boundaries for their region of interest (**Not yet implemented**).\n",
    "\n",
    "- The corresponding 3DEP point cloud dataset is accessed programmatically from the <a href=\"https://registry.opendata.aws/usgs-lidar/\"> Amazon Web Services (AWS) public EPT (Entwine Point Tile) bucket</a>, implementing the user-defined AOI and made available for subsequent processing.\n",
    "\n",
    "- Flexibile and customizable PDAL pipelines are available for reclassifying, filtering, and computing derivate products based on user-defined specifications.\n",
    " \n",
    "- DEM (DTM/DSM) generation with option to save (or not) point cloud data.\n",
    "\n",
    "- Point cloud data and/or derivative products are saved to local directory or local path defined by user.\n",
    "\n",
    "<h4>Additional resources</h4>\n",
    "Two additional Python-based workflow have been developed and are availble in Jupyter Notebook format for: <br>\n",
    "  \n",
    "1. <a href=\"https://github.com/cmspeed/OT_3DEP_Workflows/blob/main/notebooks/Programmatically_accessing_3DEP_data_using_USGS_7.5_Quadrangles.ipynb\"> Programmatically accessing, processing, and visualizing 3DEP data using USGS 7.5' Quadrangles</a>. <br>\n",
    "\n",
    "2. <a href=\"https://github.com/cmspeed/OT_3DEP_Workflows/blob/main/notebooks/Canopy_Height_Model_From_3DEP_Data.ipynb\"> Accessing 3DEP point cloud data and creating a canopy height model (CHM) </a>.\n",
    "    \n",
    "<h2>Funding</h2>\n",
    "<a id='#Funding'></a>\n",
    "\n",
    "<h2>Keywords</h2>\n",
    "<a id='#Keywords'></a>\n",
    "\n",
    "keywords=[\"OpenTopography\",\"USGS\", \"3DEP\", \"PDAL\"]\n",
    "\n",
    "<h2>Citation</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83dbc2a",
   "metadata": {},
   "source": [
    "## 6. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e20850",
   "metadata": {},
   "source": [
    "### 6.1 Getting Started\n",
    "This notebook provides a self-contained workflow for accessing, processing, and visualizing 3DEP point cloud data. There are two options for performing this workflow:\n",
    "\n",
    "1. Download this Jupyter notebook (.ipynb file) to your local file system. \n",
    "    - Create a virtual environement containing the required dependencies (see below).\n",
    "    - Run Juypter notebook on local machine.\n",
    "    - Data download limits will be dependent on user's available hard drive storage.\n",
    "    <br/><br/>\n",
    "2. Launch the interactive Jupyter notebook on Google Colaboratory.\n",
    "    - Does not require creation of a virtual environment or installation on local filesystem.\n",
    "    - Requires Google account and access to personal Google Drive folder.\n",
    "    - Data download limits will be dependent on user's available Google Drive storage. \n",
    "    - If you wish to run this notebook in Google Colaboratory click the 'Open in Colab' badge below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d6904",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cmspeed/OT_3DEP_Workflows/blob/main/notebooks/3DEP_pointcloud_access_processing_DTM_creation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-vampire",
   "metadata": {},
   "source": [
    "<h3> 6.1 Library Imports</h3>\n",
    "<a id='#Library-Imports-6.1'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e061331",
   "metadata": {},
   "source": [
    "### (Optional) - Run Notebook in Google Colaboratory Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exectute this block of cells if running on Google Colab\n",
    "!git clone https://github.com/cmspeed/OT_3DEP_Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs Conda, which is the easiest way to install PDAL in the Google Colab environment\n",
    "# This will trigger a notification that the \"Your session crashed for an unknown reason.\" \n",
    "# This is normal. Execute next cell.\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28780b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Conda and install PDAL ---- Takes 1-2 minutes\n",
    "import condacolab\n",
    "condacolab.check()\n",
    "!mamba install -q python-pdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5164b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Install the remaining dependencies\n",
    "!pip install -r OT_3DEP_Workflows/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount your Google Drive for saving content\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages (Google Colab Only)\n",
    "import os\n",
    "import json\n",
    "import pdal\n",
    "import gdal\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyleaflet\n",
    "import ipywidgets as widgets\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "from shapely.ops import transform\n",
    "import requests\n",
    "import pyproj\n",
    "from pyproj.aoi import AreaOfInterest\n",
    "from pyproj.database import query_utm_crs_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e571d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Runtime must be restarted after the above executes before import of PDAL will be successful!\n",
    "### On Google Colab ribbon click \"Runtime\" > \"Restart Runtime\".  \n",
    "### Do not execute any of the previous cells. Execute the following cells only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e157d8",
   "metadata": {},
   "source": [
    "**If running Google Colab, proceed to 6.2 Define Functions, and do not run next cell (6.1.2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c67c1",
   "metadata": {},
   "source": [
    "#### 6.1.2.  Option 2 - Install and Run Notebook on Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-questionnaire",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Packages (Local Machine Only)\n",
    "import os\n",
    "import json\n",
    "import pdal\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyleaflet\n",
    "import ipywidgets as widgets\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "from shapely.ops import transform\n",
    "import requests\n",
    "import pyproj\n",
    "from pyproj.aoi import AreaOfInterest\n",
    "from pyproj.database import query_utm_crs_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1299e5e",
   "metadata": {},
   "source": [
    "<h3>6.2 Define Functions</h3>\n",
    "<a id='#Define-Functions-6.2'></a>\n",
    "\n",
    "The functions below are used throughout the rest of the notebook and are included here for clarity.\n",
    "\n",
    "```gcs_to_proj()``` is a function to project from geographic coordinates, WGS84 (EPSG: 4326), to Web Mercator projection (EPSG: 3857).\n",
    "\n",
    "```import_shapefile_to_shapely()``` is a function to read a user's shapefile and make a shapely object.\n",
    "\n",
    "```handle_draw()``` is a function for interactive drawing on ipyleaflet maps and storing the polygon for use in requesting point cloud data.\n",
    "\n",
    "```build_pdal_pipeline()``` is a function used to construct the pdal pipeline to request/process the point cloud data from AWS ept public bucket.\n",
    "\n",
    "```make_DEM_pipeline``` is a function used to construct pdal pipeline to perform steps in ```build_pdal_pipeline()``` and create a DEM (DSM or DTM) from the point cloud data.\n",
    "\n",
    "These functions can be modified as the user sees fit; however, they are designed to work 'out of the box'.\n",
    "\n",
    "**Modify this to reproject from ANY CRS to 3857** <br>\n",
    "**Modify to use | for clarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924c977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gcs_to_proj(poly):\n",
    "    \"\"\"\n",
    "    Function for reprojecting polygon shapely object from geographic coordinates (EPSG:4326) \n",
    "    to Web Mercator (EPSG: 3857)). \n",
    "    \n",
    "    :param poly: shapely polygon for user area of interest (AOI)\n",
    "    \"\"\"\n",
    "    wgs84 = pyproj.CRS(\"EPSG:4326\")\n",
    "    web_mercator = pyproj.CRS(\"EPSG:3857\")\n",
    "    project = pyproj.Transformer.from_crs(wgs84, web_mercator, always_xy=True).transform\n",
    "    user_poly_proj3857 = transform(project, poly)\n",
    "    return(user_poly_proj3857)\n",
    "\n",
    "def import_shapefile_to_shapely(path):\n",
    "    \"\"\"\n",
    "    Conversion of shapefile to shapely object.\n",
    "    \n",
    "    :param path: location of shapefile on user's local filesystem\n",
    "    \"\"\"\n",
    "    shapefile_path = path\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    user_shp = gdf.loc[0, 'geometry']\n",
    "    user_shp_epsg3857 = gcs_to_proj(user_shp)\n",
    "    user_AOI = [[user_shp, user_shp_epsg3857]]\n",
    "    return user_AOI\n",
    "    \n",
    "def handle_draw(target, action, geo_json):\n",
    "    \"\"\"\n",
    "    Allow user to draw area of interest (AOI) on interactive ipyleaflet map.\n",
    "    \n",
    "    :param extent_epsg3857: polygon for user-defined AOI\n",
    "    :param usgs_3dep_dataset_name: name of 3DEP dataset which AOI overlaps\n",
    "    :param resolution: The desired resolution of the pointcloud based on the following definition:\n",
    "    \"\"\"\n",
    "        \n",
    "    geom = dict(geo_json['geometry'])\n",
    "    user_poly = shape(geom)\n",
    "    user_poly_proj3857 = gcs_to_proj(user_poly)\n",
    "    print('AOI is valid and has boundaries of ', user_poly_proj3857.bounds)\n",
    "    user_AOI.append((user_poly, user_poly_proj3857))  #for various reasons, we need user AOI in GCS and EPSG 3857\n",
    "\n",
    "def build_pdal_pipeline(extent_epsg3857, usgs_3dep_dataset_names, pc_resolution, filterNoise = False,\n",
    "                        reclassify = True, savePointCloud = True, pc_outName = 'filter_test', pc_outType = 'laz'):\n",
    "\n",
    "    \"\"\"\n",
    "    Build pdal pipeline for requesting, processing, and saving point cloud data.\n",
    "    \n",
    "    Parameters:\n",
    "    :param extent_epsg3857: Polygon for user-defined AOI in Web Mercator projection (EPS:3857)\n",
    "                            usgs_3dep_dataset_name: name of 3DEP dataset which AOI overlaps. Polygon is generated \n",
    "                            either through the 'handle_draw' methor or by inputing their own coordinates.\n",
    "                            This parameter is set automatically when the user-defined AOI is chosen.\n",
    "    :param usgs_3dep_dataset_names: List of name of the 3DEP dataset(s) that the data will be obtained. This parameter is set \n",
    "                                automatically when the user-defined AOI is chosen.\n",
    "    :param pc_resolution: The desired resolution of the pointcloud based on the following definition:\n",
    "        \n",
    "                        Source: https://pdal.io/stages/readers.ept.html#readers-ept\n",
    "                            A point resolution limit to select, expressed as a grid cell edge length. \n",
    "                            Units correspond to resource coordinate system units. For example, \n",
    "                            for a coordinate system expressed in meters, a resolution value of 0.1 \n",
    "                            will select points up to a ground resolution of 100 points per square meter.\n",
    "                            The resulting resolution may not be exactly this value: the minimum possible \n",
    "                            resolution that is at least as precise as the requested resolution will be selected. \n",
    "                            Therefore the result may be a bit more precise than requested.\n",
    "                            \n",
    "    :param filterNoise: Option to remove points from USGS Class 7 (noise).\n",
    "    :param savePointCloud: Option to save (or not) the point cloud dataset.\n",
    "    :param pc_outName: Desired name of file on user's local filesystem. If savePointcloud = False, \n",
    "                       this should be outName = ''\n",
    "    :param pc_outType:  Desired file extension. Input must be either 'las' or 'laz'. If a different file type is\n",
    "    :param requested,the user will get error stating \"Extension must be 'las' or 'laz'\". If savePointcloud = False, \n",
    "        this should be outType = ''\n",
    "    :raise Exception: If user passes in argument that is not 'dtm' or 'dsm'\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/{}/ept.json\".format(usgs_3dep_dataset_name)\n",
    "    \n",
    "    ### TODO: Add an option to choose an output CRS\n",
    "    ### TODO: Add option to output shapefile of the bounding box. \n",
    "    ### TODO: Consider restructuring pipeline construction with list comprehension\n",
    "              #pipline = [dict(zip([1],[stage])) for x in range(1,len(stages))], or similar.\n",
    "    ### Important note: smrf cannot be run in streaming mode\n",
    "    ### TODO: Test performance in and out of streaming mode. Could create a execute_pipeline() \n",
    "        ###   that tests whether streaming is possible.\n",
    "        \n",
    "    #this is the basic pipeline which only accesses the 3DEP data. There is an optional\n",
    "    pointcloud_pipeline = {\n",
    "            \"pipeline\": [\n",
    "                \n",
    "                {\n",
    "                    \"type\": \"readers.ept\",\n",
    "                    \"filename\": str(url),\n",
    "                    \"polygon\": str(extent_epsg3857),\n",
    "                    \"requests\": 3,\n",
    "                    \"resolution\": pc_resolution\n",
    "                }\n",
    "            ]\n",
    "    }\n",
    "    \n",
    "    if filterNoise == True:\n",
    "        \n",
    "        filter_stage = {\n",
    "            \"type\":\"filters.range\",\n",
    "            \"limits\":\"Classification![7:7], Classification![18:18]\"\n",
    "        }\n",
    "        \n",
    "        pointcloud_pipeline['pipeline'].append(filter_stage)\n",
    "    \n",
    "    if reclassify == True:\n",
    "        \n",
    "        remove_classes_stage = {\n",
    "            \"type\":\"filters.assign\",\n",
    "            \"value\":\"Classification = 0\"\n",
    "        }\n",
    "        \n",
    "        classify_ground_stage = {\n",
    "            \"type\":\"filters.smrf\"\n",
    "        }\n",
    "        \n",
    "        reclass_stage = {\n",
    "            \"type\":\"filters.range\",\n",
    "            \"limits\":\"Classification[2:2]\"\n",
    "        }\n",
    "        \n",
    "        pointcloud_pipeline['pipeline'].append(remove_classes_stage)\n",
    "        pointcloud_pipeline['pipeline'].append(classify_ground_stage)\n",
    "        pointcloud_pipeline['pipeline'].append(reclass_stage)\n",
    "        \n",
    "    if savePointCloud == True:\n",
    "        \n",
    "        if pc_outType == 'las':\n",
    "            savePC_stage = {\n",
    "                \"type\": \"writers.las\",\n",
    "                \"filename\": str(pc_outName)+'.'+ str(pc_outType)\n",
    "            }\n",
    "        elif pc_outType == 'laz':    \n",
    "            savePC_stage = {\n",
    "                \"type\": \"writers.las\",\n",
    "                \"compression\": \"laszip\",\n",
    "                \"filename\": str(pc_outName)+'.'+ str(pc_outType)\n",
    "            }\n",
    "        else:\n",
    "            raise Exception(\"pc_outType must be 'las' or 'laz'.\")\n",
    "\n",
    "        pointcloud_pipeline['pipeline'].append(savePC_stage)\n",
    "        \n",
    "    return pointcloud_pipeline\n",
    "\n",
    "\n",
    "def make_DEM_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pc_resolution, dem_resolution,\n",
    "                      filterNoise = True, reclassify = True, savePointCloud = False, pc_outName = 'filter_test', \n",
    "                      pc_outType = 'laz', demType = 'dtm', gridMethod = 'idw', dem_outName = 'dem_test', \n",
    "                      dem_outExt = 'tif', driver = \"GTiff\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Build pdal pipeline for creating a digital elevation model (DEM) product from the requested point cloud data. The \n",
    "    user must specify whether a digital terrain (bare earth) model (DTM) or digital surface model (DSM) will be created, \n",
    "    the output DTM/DSM resolution, and the gridding method desired. \n",
    "\n",
    "    The `build_pdal_pipeline() method is used to request the data from the Amazon Web Services ept bucket, and the \n",
    "    user may define any processing steps (filtering or reclassifying). The user must also specify whether the point \n",
    "    cloud should be saved or not. Saving the point cloud is not necessary for the generation of the DEM. \n",
    "\n",
    "    \n",
    "    :param extent_epsg3857: Polygon for user-defined AOI in Web Mercator projection (EPS:3857)\n",
    "                         usgs_3dep_dataset_name: name of 3DEP dataset which AOI overlaps. Polygon is generated \n",
    "                         either through the 'handle_draw' methor or by inputing their own coordinates.\n",
    "                         This parameter is set automatically when the user-defined AOI is chosen.\n",
    "    :param usgs_3dep_dataset_name: Name of the 3DEP dataset that the data will be obtained. This parameter is set \n",
    "                                automatically when the user-defined AOI is chosen.\n",
    "    :param pc_resolution: The desired resolution of the pointcloud based on the following definition:\n",
    "\n",
    "                        Source: https://pdal.io/stages/readers.ept.html#readers-ept\n",
    "                            A point resolution limit to select, expressed as a grid cell edge length. \n",
    "                            Units correspond to resource coordinate system units. For example, \n",
    "                            for a coordinate system expressed in meters, a resolution value of 0.1 \n",
    "                            will select points up to a ground resolution of 100 points per square meter.\n",
    "                            The resulting resolution may not be exactly this value: the minimum possible \n",
    "                            resolution that is at least as precise as the requested resolution will be selected. \n",
    "                            Therefore the result may be a bit more precise than requested.\n",
    "\n",
    "    :param dem_resolution: Desired grid size (in meteres) for output raster DEM \n",
    "    :param filterNoise: Option to remove points from USGS Class 7 (noise).\n",
    "    :param savePointCloud: Option to save (or not) the point cloud dataset.\n",
    "    :param pc_outName: Desired name of file on user's local filesystem. If savePointcloud = False, \n",
    "                  this should be outName = ''\n",
    "    :param pc_outType:  Desired file extension. Input must be either 'las' or 'laz'. If a different file type is requested,\n",
    "                  the user will get error stating \"Extension must be 'las' or 'laz'\". If savePointcloud = False, \n",
    "                  this should be outType = ''\n",
    "    :param demType: Type of DEM produced. Input must 'dtm' (digital terrain model) or 'dsm' (digital surface model).\n",
    "    :param gridMethod: Method used. Options are 'min', 'mean', 'max', 'idw'. ELABORATE MORE HERE.\n",
    "    :param dem_outName: Desired name of DEM file on user's local filesystem.\n",
    "    :param dem_outExt: DEM file extension. ELABORATE MORE HERE.\n",
    "    :param driver: Driver used. ELABORATE MORE HERE.\n",
    "    :raise Exception: If user passes in argument that is not 'dtm' or 'dsm'\n",
    "    \"\"\"\n",
    "\n",
    "    dem_pipeline = build_pdal_pipeline(extent_epsg3857, usgs_3dep_dataset_name, pc_resolution,\n",
    "                                              filterNoise, reclassify, savePointCloud, pc_outName, pc_outType)\n",
    "    \n",
    "    if demType == 'dsm':\n",
    "        dem_stage = {\n",
    "                \"type\":\"writers.gdal\",\n",
    "                \"filename\":str(dem_outName)+ '.' + str(dem_outExt),\n",
    "                \"gdaldriver\":driver,\n",
    "                \"nodata\":-9999,\n",
    "                \"output_type\":gridMethod,\n",
    "                \"resolution\":float(dem_resolution),\n",
    "                \"gdalopts\":\"COMPRESS=LZW,TILED=YES,blockxsize=256,blockysize=256,COPY_SRC_OVERVIEWS=YES\"\n",
    "        }\n",
    "    \n",
    "    elif demType == 'dtm':\n",
    "        groundfilter_stage = {\n",
    "                \"type\":\"filters.range\",\n",
    "                \"limits\":\"Classification[2:2]\"\n",
    "        }\n",
    "\n",
    "        dem_pipeline['pipeline'].append(groundfilter_stage)\n",
    "\n",
    "        dem_stage = {\n",
    "                \"type\":\"writers.gdal\",\n",
    "                \"filename\":str(dem_outName)+ '.' + str(dem_outExt),\n",
    "                \"gdaldriver\":driver,\n",
    "                \"nodata\":-9999,\n",
    "                \"output_type\":gridMethod,\n",
    "                \"resolution\":float(dem_resolution),\n",
    "                \"gdalopts\":\"COMPRESS=LZW,TILED=YES,blockxsize=256,blockysize=256,COPY_SRC_OVERVIEWS=YES\"\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"demType must be 'dsm' or 'dtm'.\")\n",
    "        \n",
    "        \n",
    "    dem_pipeline['pipeline'].append(dem_stage)\n",
    "    \n",
    "    return dem_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433ad51",
   "metadata": {},
   "source": [
    "## 7. Data Access and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ecbeb2",
   "metadata": {},
   "source": [
    "<h3> 7.1 Access 3DEP Data Polygons</h3>\n",
    "<a id='#Access-3DEP-Data-7.1'></a>\n",
    "\n",
    "Executing the next two cells will allow you to select a Area of Interest (AOI) for which point cloud data will be retreived. The map includes a Geo\n",
    "JSON file indicating where 3DEP point cloud data are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a267308",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get GeoJSON file for 3DEP outlines from URL \n",
    "\n",
    "#this needs to be modified to always make a new pull, even if it exists because it is possible updated at the source.\n",
    "url = 'https://raw.githubusercontent.com/hobuinc/usgs-lidar/master/boundaries/resources.geojson'\n",
    "r = requests.get(url)\n",
    "with open('resources.geojson', 'w') as f:\n",
    "    f.write(r.content.decode(\"utf-8\"))\n",
    "\n",
    "with open('resources.geojson', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "geo_json_3DEP = ipyleaflet.GeoJSON(data=data, style = {'color': 'green', 'opacity':1, \n",
    "                                       'weight':1.9, 'fillOpacity':0.1})\n",
    "\n",
    "with open('resources.geojson', 'r') as f:\n",
    "    df = gpd.read_file(f)\n",
    "\n",
    "projected_geoms = []\n",
    "for geometry in df['geometry']:\n",
    "        projected_geoms.append(gcs_to_proj(geometry))\n",
    "\n",
    "print('Done. 3DEP polygons downloaded and reprojected to Web Mercator (EPSG:3857)')\n",
    "\n",
    "geometries_GCS = df['geometry']\n",
    "geometries_EPSG3857 = gpd.GeoSeries(projected_geoms)\n",
    "names = df['name']\n",
    "urls = df['url']\n",
    "\n",
    "num_points = df['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86389e5e",
   "metadata": {},
   "source": [
    "<h3> 7.2 Create Interactive Ipyleaflet Map and Define AOI</h3>\n",
    "<a id='#Create-Interactive-Ipyleaflet-Map-And-Define-AOI-7.2'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter shapefile path, if applicable. Otherwise leave as shapefile_path = ''\n",
    "# shapefile_path = '/Users/cole/Dropbox/unavco/project/ot_repo/OT_3DEP_Workflows/shapefiles/test_shp.shp'\n",
    "shapefile_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7cc4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = ipyleaflet.Map(\n",
    "    basemap=ipyleaflet.basemaps.Esri.WorldTopoMap,\n",
    "    center=(39, -100),\n",
    "    zoom=3,\n",
    "    crs=ipyleaflet.projections.EPSG3857\n",
    "    )\n",
    "\n",
    "m.add_layer(geo_json_3DEP)  #add 3DEP polygons GeoJSON\n",
    "\n",
    "dc = ipyleaflet.DrawControl(\n",
    "    marker={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "    rectangle={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "    circle={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "    circlemarker={},\n",
    ")\n",
    "\n",
    "if os.path.exists(shapefile_path):\n",
    "    user_AOI = import_shapefile_to_shapely(shapefile_path)\n",
    "    print('shapefile loaded. proceed to next cell')\n",
    "    \n",
    "else:\n",
    "    print('Select an Area of Interest using the tools on the left side of the map or enter your own coordinates below')\n",
    "    user_AOI = []\n",
    "    dc.on_draw(handle_draw)\n",
    "    m.add_control(dc)\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54758f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify desired point cloud resolution\n",
    "AOI_GCS = user_AOI[0][0]\n",
    "AOI_EPSG3857 = user_AOI[0][1]\n",
    "centroid =  list(AOI_GCS.centroid.coords)[0]\n",
    "\n",
    "intersecting_polys = []\n",
    "for i,geom in enumerate(geometries_EPSG3857):\n",
    "    if geom.intersects(AOI_EPSG3857):\n",
    "        intersecting_polys.append((names[i], geometries_GCS[i], geometries_EPSG3857[i], urls[i], num_points[i]))\n",
    "        \n",
    "m = ipyleaflet.Map(\n",
    "    basemap=ipyleaflet.basemaps.Esri.WorldTopoMap,\n",
    "    center=(centroid[1],centroid[0]),\n",
    "    zoom=12,\n",
    "    )\n",
    "\n",
    "wlayer_3DEP_list = []\n",
    "usgs_3dep_datasets = []\n",
    "number_pts_est = []\n",
    "for i, poly in enumerate(intersecting_polys):\n",
    "    wlayer_3DEP = ipyleaflet.WKTLayer(\n",
    "        wkt_string=poly[1].wkt, \n",
    "        style={\"color\": \"green\"}, hover_style={\"fillColor\": \"red\"})\n",
    "    \n",
    "    m.add_layer(wlayer_3DEP)\n",
    "    wlayer_3DEP_list.append(wlayer_3DEP)\n",
    "    \n",
    "    usgs_3dep_datasets.append(poly[0])\n",
    "    number_pts_est.append((int((AOI_EPSG3857.area/poly[2].area)*(poly[4]))))\n",
    "\n",
    "wlayer_user = ipyleaflet.WKTLayer(\n",
    "    wkt_string=AOI_GCS.boundary.wkt,\n",
    "    style={\"color\": \"blue\"}\n",
    ")\n",
    "\n",
    "AOI_EPSG3857_wtk = AOI_EPSG3857.wkt\n",
    "\n",
    "m.add_layer(wlayer_user)\n",
    "\n",
    "area = int(AOI_EPSG3857.area/1e6)\n",
    "num_pts_est = sum(number_pts_est)\n",
    "user_resolution = widgets.RadioButtons(\n",
    "    options=[\n",
    "        (f'Full - All ~{int(num_pts_est):,} points', 1.0),\n",
    "        (f'High - 2m resolution ~{int(num_pts_est/2):,} points', 2.0),\n",
    "        (f'Mid  - 5m resolution ~{int(num_pts_est/5):,} points', 5.0),\n",
    "        (f'Low  - 10m resolution ~{int(num_pts_est/10):,} points', 10.0)\n",
    "    ],\n",
    "    layout={'width': 'max-content'},\n",
    "    disabled = False,\n",
    ")\n",
    "# widgets.VBox(\n",
    "#     [m,\n",
    "#         widgets.Label(value=f'Full dataset will consist of ~{num_pts_est:,} \\\n",
    "#         points from the {usgs_3dep_dataset} 3DEP dataset, or choose desired resolution below.'),\n",
    "#         user_resolution\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "widgets.VBox(\n",
    "    [m,\n",
    "        widgets.Label(value=f'Full dataset will consist of ~{num_pts_est:,} \\\n",
    "        points, or choose desired resolution below.'),\n",
    "        user_resolution\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990899f",
   "metadata": {},
   "source": [
    "## 8. Data Processing\n",
    "PDAL pipelines are useful ways of processing and manipulating point cloud data and creating derivative products. Below you will need to define the processing and/or derivative products which you desire. The ```build_pdal_pipeline()``` function will then construct the appropriate pipeline designed for the user's specifications. Executing this pipeline will request and perform processing on the point cloud data and provide the final result on the user's filesystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f17c46",
   "metadata": {},
   "source": [
    "### 8.1 Construct PDAL Pipeline\n",
    "The PDAL pipeline is constructed using the ```build_pdal_pipeline()``` function. Explanations of input parameters are can be found in this cell. Importantly, the ```outputs``` parameter is where the user may define the processing and outputs that they wish to produce. \n",
    "\n",
    "Paramaters: <br>\n",
    "```AOI_EPSG3857_wtk```: the user-defined area of interest (AOI)<br>\n",
    "```usgs_3dep_dataset```: the corresponding 3DEP dataset name<br>\n",
    "```pointcloud_resolution```: point cloud resolution (1m, 2m, 5m, 10m)<br>\n",
    "```filterNoise```: remove the points of Class 7 (noise); optional<br>\n",
    "```reclassify```: remove USGS classes and run an SMRF to classify ground points only; optional<br>\n",
    "```savePointCloud```: specify if point cloud data should be saved to local file system; optional<br>\n",
    "```pc_outName```: name of point cloud on local file system<br>\n",
    "```pc_outType```: file type, |las or laz (laszip compression). Options are 'las' or 'laz'<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555ea11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirname = '/Users/cole/Dropbox/unavco/project/ot_repo/OT_3DEP_Workflows/notebooks/resolution_tests/'\n",
    "pointcloud_resolution = user_resolution.value\n",
    "pc_pipeline = build_pdal_pipeline(AOI_EPSG3857_wtk, usgs_3dep_datasets, pointcloud_resolution, filterNoise = True,\n",
    "                                  reclassify = False, savePointCloud = True, pc_outName = dirname+'agra_mid',\n",
    "                                  pc_outType = 'laz')\n",
    "\n",
    "pc_pipeline = pdal.Pipeline(json.dumps(pc_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d7cb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pc_pipeline.execute_streaming(chunk_size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da107b41",
   "metadata": {},
   "source": [
    "If the user only desires point cloud data, they may stop here. Following is a quick overview showing how ground class may be gridded to create a DTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ed7a5",
   "metadata": {},
   "source": [
    "### 8.2 (Optional) DEM generation \n",
    "The following pipeline performs the above ```build_pdal_pipeline()``` method and also performs the ```make_DEM_pipeline()``` to produce a DEM (user chooses DSM or DTM). \n",
    "\n",
    "Paramaters:  <br>\n",
    "```AOI_EPSG3857_wtk```: the user-defined area of interest (AOI)<br>\n",
    "```usgs_3dep_dataset```: the corresponding 3DEP dataset name<br>\n",
    "```pointcloud_resolution```: point cloud resolution (1m, 2m, 5m, 10m)<br>\n",
    "```dem_generation```: grid size for dem product (specified in meters)<br>\n",
    "```filterNoise```: remove the points of Class 7 (noise); optional<br>\n",
    "```reclassify```: remove USGS classes and run an SMRF to classify ground points only; optional<br>\n",
    "```savePointCloud```: specify if point cloud data should be saved to local file system; optional<br>\n",
    "```pc_outName```: name of point cloud on local file system<br>\n",
    "```pc_outType```: file type, las or laz (laszip compression). Options are 'las' or 'laz'<br>\n",
    "```demType```: specifies to create digital surface model (DSM) or digital terrain model (DTM)<br>\n",
    "```gridMethod```: gridding method to use; options: (min, mean, max, idw)<br>\n",
    "```dem_outName```: name of dem on local file system <br>\n",
    "```dem_outExt```: extension of file on local file system (must correspond to what is chosen for ```driver```<br>\n",
    "```driver```: gdal code of the driver (default is \"GTiff\"; other options can be found at https://gdal.org/drivers/raster/index.html<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564000a",
   "metadata": {},
   "source": [
    "### Make DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e23c3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dem_resolution = 2.0\n",
    "dirname = '/Users/cole/Dropbox/unavco/project/ot_repo/OT_3DEP_Workflows/notebooks/resolution_tests/dems/'\n",
    "dem_pipeline = make_DEM_pipeline(AOI_EPSG3857_wtk, usgs_3dep_datasets, pointcloud_resolution, dem_resolution,\n",
    "                                 filterNoise = True, reclassify = False,  savePointCloud = False, pc_outName = '', \n",
    "                                 pc_outType = '', demType = 'dsm', gridMethod='idw', \n",
    "                                 dem_outName = dirname+'agra_2m_dsm', dem_outExt = 'tif', driver = \"GTiff\")\n",
    "\n",
    "dem_pipeline = pdal.Pipeline(json.dumps(dem_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749cf45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dem_pipeline.execute_streaming(chunk_size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de2d50",
   "metadata": {},
   "source": [
    "### Make DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06655269",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dem_resolution = 2.0\n",
    "dirname = '/Users/cole/Dropbox/unavco/project/ot_repo/OT_3DEP_Workflows/notebooks/resolution_tests/dems/'\n",
    "dem_pipeline = make_DEM_pipeline(AOI_EPSG3857_wtk, usgs_3dep_dataset, pointcloud_resolution, dem_resolution,\n",
    "                                 filterNoise = True, reclassify = False, savePointCloud = False, pc_outName = '', \n",
    "                                 pc_outType = '', demType = 'dtm', dem_outName = dirname+'anchorage_2m_dtm', \n",
    "                                 dem_outExt = 'tif', driver = \"GTiff\")\n",
    "\n",
    "dem_pipeline = pdal.Pipeline(json.dumps(dem_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59ee07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dem_pipeline.execute_streaming(chunk_size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8990d5",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualize the DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94819b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dem_outName = dirname+'anchorage_2m_dtm'\n",
    "dem_outExt = 'tif'\n",
    "filename = dem_outName+'.'+dem_outExt\n",
    "gdal_data = gdal.Open(filename)\n",
    "gdal_band = gdal_data.GetRasterBand(1)\n",
    "nodataval = gdal_band.GetNoDataValue()\n",
    "\n",
    "# convert to a numpy array\n",
    "data_array = gdal_data.ReadAsArray().astype(float)\n",
    "data_array\n",
    "\n",
    "# replace missing values if necessary\n",
    "if np.any(data_array == nodataval):\n",
    "    data_array[data_array == nodataval] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13794fde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (15,15))\n",
    "masked_array = np.ma.array (data_array, mask=np.isnan(data_array))\n",
    "cmap = matplotlib.cm.get_cmap(\"Greys\").copy()\n",
    "cmap.set_bad('white',1.)\n",
    "ax.imshow(masked_array, interpolation='nearest', cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c4c69",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook provides a workflow for programmatically accessing, processing, and visualizing point cloud and derivative products for a user-defined AOI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf65c16",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
